{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6b8fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "694d9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "test_data= datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48dc2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1,),\n",
    "\n",
    "    'test': DataLoader(train_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1,)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "469ae314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2bad99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b662120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamka\\AppData\\Local\\Temp\\ipykernel_32956\\787333203.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302943\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.290434\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.208826\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.100144\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.925702\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.834702\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.750961\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.778071\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.757833\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.795713\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.734541\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.708520\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.740305\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.689107\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.654767\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.623110\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.618101\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 1.643865\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 1.631402\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 1.590620\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.583289\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.608640\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 1.594850\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 1.607527\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.592542\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 1.590759\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 1.556049\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 1.601776\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 1.555577\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 1.607436\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 56280/60000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.568086\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 1.559623\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 1.576518\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 1.542339\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 1.524090\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 1.602340\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 1.626312\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 1.589682\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.596133\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 1.576513\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 1.578515\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 1.538839\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 1.585873\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 1.584330\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 1.559298\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 1.550003\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.617492\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 1.630004\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 1.543835\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 1.604765\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 1.645808\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 1.578144\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 1.570600\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 1.586187\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.622864\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 1.568131\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 1.627238\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 1.521271\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 1.508256\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 1.544611\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 57359/60000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.529095\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 1.547322\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 1.536253\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 1.570750\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 1.586054\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 1.580601\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 1.549194\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 1.550923\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.546696\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 1.549047\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 1.583566\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 1.511853\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 1.563447\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 1.568292\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 1.581726\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 1.521226\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.549786\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 1.578652\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 1.544167\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 1.532121\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 1.550424\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 1.545583\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 1.561824\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 1.563783\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.586784\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 1.554902\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 1.519775\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 1.526907\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 1.527542\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 1.534824\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 57557/60000 (96%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.513638\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 1.559416\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 1.533561\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 1.538121\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 1.569002\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 1.548127\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 1.573906\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 1.526834\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.537810\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 1.562284\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 1.497294\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 1.565635\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 1.545940\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 1.588944\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 1.522413\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 1.558695\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.537478\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 1.561093\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 1.543094\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 1.534095\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 1.531119\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 1.551876\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 1.565877\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 1.566699\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.522648\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 1.536560\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 1.500614\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 1.544993\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 1.569522\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 1.539025\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 57928/60000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.548050\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 1.527848\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 1.525230\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 1.526958\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 1.567466\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 1.502603\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 1.544976\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 1.544691\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.534236\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 1.574655\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 1.550548\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 1.537979\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 1.524724\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 1.558496\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 1.547280\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 1.551114\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.535747\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 1.502205\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 1.542466\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 1.530959\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 1.561262\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 1.506028\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 1.559551\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 1.494130\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.534203\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 1.501482\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 1.539860\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 1.516954\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 1.521835\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 1.497829\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 58124/60000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.541016\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 1.513824\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 1.552813\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 1.524391\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 1.495213\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 1.519119\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 1.517718\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 1.561726\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 1.492456\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 1.513859\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 1.571445\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 1.518567\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 1.556049\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 1.540350\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 1.558383\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 1.562008\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 1.578238\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 1.504219\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 1.555047\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 1.554703\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 1.541305\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 1.559857\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 1.532492\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 1.564942\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 1.541440\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 1.598264\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 1.494570\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 1.528519\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 1.510011\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 1.570669\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 58166/60000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.514022\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 1.586098\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 1.573630\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 1.522866\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 1.534709\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 1.519327\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 1.483541\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 1.514991\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 1.524748\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 1.491665\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 1.531988\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 1.496635\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 1.492464\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 1.514060\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 1.497257\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 1.507508\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 1.541337\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 1.521358\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 1.511283\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 1.544375\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 1.541262\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 1.504840\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 1.520036\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 1.490804\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 1.514917\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 1.539086\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 1.545302\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 1.571198\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 1.493394\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 1.570372\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 58232/60000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.526190\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 1.525524\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 1.520737\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 1.526736\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 1.536052\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 1.545161\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 1.491863\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 1.532642\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 1.538897\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 1.472957\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 1.497043\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 1.525849\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 1.537215\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 1.496713\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 1.513619\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 1.519036\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 1.549217\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 1.508827\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 1.543683\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 1.513478\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 1.528293\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 1.499524\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 1.511807\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 1.539738\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 1.571744\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 1.526084\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 1.584124\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 1.509156\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 1.509132\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 1.503324\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 58306/60000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.509225\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 1.543861\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 1.548965\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 1.504358\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 1.532562\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 1.513920\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 1.525075\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 1.528230\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 1.494467\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 1.534425\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 1.558990\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 1.542019\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 1.590549\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 1.528646\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 1.532180\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 1.536724\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 1.559021\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 1.509059\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 1.536400\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 1.531577\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 1.519354\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 1.501215\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 1.514238\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 1.535896\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 1.536937\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 1.486367\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 1.529436\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 1.543091\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 1.534205\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 1.482407\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 58347/60000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.512391\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 1.549940\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 1.545879\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 1.488027\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 1.497516\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 1.526787\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 1.505819\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 1.541355\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 1.526501\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 1.522537\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 1.512383\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 1.540930\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 1.611452\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 1.476484\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 1.504151\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 1.496546\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 1.539346\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 1.499898\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 1.546704\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 1.561071\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 1.500191\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 1.515211\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 1.595093\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 1.512719\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 1.540317\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 1.506207\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 1.481781\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 1.501542\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 1.533947\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 1.495804\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 58498/60000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a585eb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 9, Actual label: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iamka\\AppData\\Local\\Temp\\ipykernel_32956\\787333203.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_data[9] # 9 is index of image\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "pred = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f'Predicted label: {pred}, Actual label: {target}')\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
